{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 456,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06578947368421052,
      "grad_norm": 3.807335376739502,
      "learning_rate": 3.860572005289598e-05,
      "loss": 0.6723,
      "step": 10
    },
    {
      "epoch": 0.13157894736842105,
      "grad_norm": 2.3869376182556152,
      "learning_rate": 3.774205741189159e-05,
      "loss": 0.6822,
      "step": 20
    },
    {
      "epoch": 0.19736842105263158,
      "grad_norm": 3.2775251865386963,
      "learning_rate": 3.6878394770887205e-05,
      "loss": 0.6109,
      "step": 30
    },
    {
      "epoch": 0.2631578947368421,
      "grad_norm": 2.94321870803833,
      "learning_rate": 3.6014732129882826e-05,
      "loss": 0.5884,
      "step": 40
    },
    {
      "epoch": 0.32894736842105265,
      "grad_norm": 3.5245068073272705,
      "learning_rate": 3.515106948887844e-05,
      "loss": 0.408,
      "step": 50
    },
    {
      "epoch": 0.39473684210526316,
      "grad_norm": 12.258198738098145,
      "learning_rate": 3.4287406847874054e-05,
      "loss": 0.472,
      "step": 60
    },
    {
      "epoch": 0.4605263157894737,
      "grad_norm": 18.061161041259766,
      "learning_rate": 3.3423744206869674e-05,
      "loss": 0.4381,
      "step": 70
    },
    {
      "epoch": 0.5263157894736842,
      "grad_norm": 7.322479248046875,
      "learning_rate": 3.256008156586529e-05,
      "loss": 0.4531,
      "step": 80
    },
    {
      "epoch": 0.5921052631578947,
      "grad_norm": 4.17413330078125,
      "learning_rate": 3.16964189248609e-05,
      "loss": 0.3575,
      "step": 90
    },
    {
      "epoch": 0.6578947368421053,
      "grad_norm": 5.859752655029297,
      "learning_rate": 3.083275628385652e-05,
      "loss": 0.4011,
      "step": 100
    },
    {
      "epoch": 0.7236842105263158,
      "grad_norm": 4.288862705230713,
      "learning_rate": 2.9969093642852133e-05,
      "loss": 0.4665,
      "step": 110
    },
    {
      "epoch": 0.7894736842105263,
      "grad_norm": 6.368010520935059,
      "learning_rate": 2.910543100184775e-05,
      "loss": 0.4526,
      "step": 120
    },
    {
      "epoch": 0.8552631578947368,
      "grad_norm": 1.5820715427398682,
      "learning_rate": 2.8241768360843364e-05,
      "loss": 0.2794,
      "step": 130
    },
    {
      "epoch": 0.9210526315789473,
      "grad_norm": 19.192241668701172,
      "learning_rate": 2.737810571983898e-05,
      "loss": 0.3955,
      "step": 140
    },
    {
      "epoch": 0.9868421052631579,
      "grad_norm": 2.842616319656372,
      "learning_rate": 2.65144430788346e-05,
      "loss": 0.3304,
      "step": 150
    },
    {
      "epoch": 1.0526315789473684,
      "grad_norm": 0.7751102447509766,
      "learning_rate": 2.5650780437830213e-05,
      "loss": 0.2732,
      "step": 160
    },
    {
      "epoch": 1.118421052631579,
      "grad_norm": 14.973968505859375,
      "learning_rate": 2.478711779682583e-05,
      "loss": 0.3014,
      "step": 170
    },
    {
      "epoch": 1.1842105263157894,
      "grad_norm": 24.565107345581055,
      "learning_rate": 2.392345515582144e-05,
      "loss": 0.3761,
      "step": 180
    },
    {
      "epoch": 1.25,
      "grad_norm": 14.644400596618652,
      "learning_rate": 2.305979251481706e-05,
      "loss": 0.2308,
      "step": 190
    },
    {
      "epoch": 1.3157894736842106,
      "grad_norm": 8.090023040771484,
      "learning_rate": 2.219612987381268e-05,
      "loss": 0.4335,
      "step": 200
    },
    {
      "epoch": 1.381578947368421,
      "grad_norm": 1.5555336475372314,
      "learning_rate": 2.133246723280829e-05,
      "loss": 0.2951,
      "step": 210
    },
    {
      "epoch": 1.4473684210526316,
      "grad_norm": 17.654531478881836,
      "learning_rate": 2.0468804591803906e-05,
      "loss": 0.2434,
      "step": 220
    },
    {
      "epoch": 1.513157894736842,
      "grad_norm": 0.3048923909664154,
      "learning_rate": 1.9605141950799523e-05,
      "loss": 0.2189,
      "step": 230
    },
    {
      "epoch": 1.5789473684210527,
      "grad_norm": 6.311356067657471,
      "learning_rate": 1.8741479309795137e-05,
      "loss": 0.2548,
      "step": 240
    },
    {
      "epoch": 1.6447368421052633,
      "grad_norm": 20.35991859436035,
      "learning_rate": 1.7877816668790754e-05,
      "loss": 0.3165,
      "step": 250
    },
    {
      "epoch": 1.7105263157894737,
      "grad_norm": 18.349790573120117,
      "learning_rate": 1.7014154027786372e-05,
      "loss": 0.3929,
      "step": 260
    },
    {
      "epoch": 1.776315789473684,
      "grad_norm": 2.264866352081299,
      "learning_rate": 1.6150491386781986e-05,
      "loss": 0.2169,
      "step": 270
    },
    {
      "epoch": 1.8421052631578947,
      "grad_norm": 4.078073501586914,
      "learning_rate": 1.52868287457776e-05,
      "loss": 0.1311,
      "step": 280
    },
    {
      "epoch": 1.9078947368421053,
      "grad_norm": 17.116971969604492,
      "learning_rate": 1.4423166104773217e-05,
      "loss": 0.1441,
      "step": 290
    },
    {
      "epoch": 1.973684210526316,
      "grad_norm": 0.5750244855880737,
      "learning_rate": 1.3559503463768834e-05,
      "loss": 0.2266,
      "step": 300
    },
    {
      "epoch": 2.039473684210526,
      "grad_norm": 11.216614723205566,
      "learning_rate": 1.269584082276445e-05,
      "loss": 0.108,
      "step": 310
    },
    {
      "epoch": 2.1052631578947367,
      "grad_norm": 0.15774264931678772,
      "learning_rate": 1.1832178181760063e-05,
      "loss": 0.046,
      "step": 320
    },
    {
      "epoch": 2.1710526315789473,
      "grad_norm": 15.657522201538086,
      "learning_rate": 1.0968515540755679e-05,
      "loss": 0.3261,
      "step": 330
    },
    {
      "epoch": 2.236842105263158,
      "grad_norm": 0.13957130908966064,
      "learning_rate": 1.0104852899751296e-05,
      "loss": 0.2231,
      "step": 340
    },
    {
      "epoch": 2.3026315789473686,
      "grad_norm": 0.17617560923099518,
      "learning_rate": 9.241190258746912e-06,
      "loss": 0.1649,
      "step": 350
    },
    {
      "epoch": 2.3684210526315788,
      "grad_norm": 5.025731563568115,
      "learning_rate": 8.377527617742527e-06,
      "loss": 0.2042,
      "step": 360
    },
    {
      "epoch": 2.4342105263157894,
      "grad_norm": 0.1396033614873886,
      "learning_rate": 7.513864976738144e-06,
      "loss": 0.1103,
      "step": 370
    },
    {
      "epoch": 2.5,
      "grad_norm": 8.060444831848145,
      "learning_rate": 6.650202335733758e-06,
      "loss": 0.112,
      "step": 380
    },
    {
      "epoch": 2.5657894736842106,
      "grad_norm": 0.40269598364830017,
      "learning_rate": 5.786539694729375e-06,
      "loss": 0.0591,
      "step": 390
    },
    {
      "epoch": 2.6315789473684212,
      "grad_norm": 3.129567861557007,
      "learning_rate": 4.92287705372499e-06,
      "loss": 0.1479,
      "step": 400
    },
    {
      "epoch": 2.6973684210526314,
      "grad_norm": 0.31955400109291077,
      "learning_rate": 4.059214412720606e-06,
      "loss": 0.0681,
      "step": 410
    },
    {
      "epoch": 2.763157894736842,
      "grad_norm": 23.833898544311523,
      "learning_rate": 3.195551771716222e-06,
      "loss": 0.1385,
      "step": 420
    },
    {
      "epoch": 2.8289473684210527,
      "grad_norm": 0.25423306226730347,
      "learning_rate": 2.3318891307118374e-06,
      "loss": 0.0714,
      "step": 430
    },
    {
      "epoch": 2.8947368421052633,
      "grad_norm": 13.153739929199219,
      "learning_rate": 1.4682264897074532e-06,
      "loss": 0.1355,
      "step": 440
    },
    {
      "epoch": 2.9605263157894735,
      "grad_norm": 0.3713667392730713,
      "learning_rate": 6.045638487030689e-07,
      "loss": 0.1332,
      "step": 450
    }
  ],
  "logging_steps": 10,
  "max_steps": 456,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 240229627462656.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
