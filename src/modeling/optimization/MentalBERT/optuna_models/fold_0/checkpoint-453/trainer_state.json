{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 453,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06622516556291391,
      "grad_norm": 5.144272804260254,
      "learning_rate": 1.3325494584651163e-05,
      "loss": 0.6664,
      "step": 10
    },
    {
      "epoch": 0.13245033112582782,
      "grad_norm": 3.4489033222198486,
      "learning_rate": 1.3025370832744605e-05,
      "loss": 0.5862,
      "step": 20
    },
    {
      "epoch": 0.1986754966887417,
      "grad_norm": 5.823989391326904,
      "learning_rate": 1.2725247080838048e-05,
      "loss": 0.6197,
      "step": 30
    },
    {
      "epoch": 0.26490066225165565,
      "grad_norm": 5.993423938751221,
      "learning_rate": 1.242512332893149e-05,
      "loss": 0.5407,
      "step": 40
    },
    {
      "epoch": 0.33112582781456956,
      "grad_norm": 4.671349048614502,
      "learning_rate": 1.2124999577024933e-05,
      "loss": 0.5036,
      "step": 50
    },
    {
      "epoch": 0.3973509933774834,
      "grad_norm": 4.485671043395996,
      "learning_rate": 1.1824875825118374e-05,
      "loss": 0.4469,
      "step": 60
    },
    {
      "epoch": 0.46357615894039733,
      "grad_norm": 7.345481872558594,
      "learning_rate": 1.1524752073211816e-05,
      "loss": 0.4973,
      "step": 70
    },
    {
      "epoch": 0.5298013245033113,
      "grad_norm": 4.926546096801758,
      "learning_rate": 1.122462832130526e-05,
      "loss": 0.4168,
      "step": 80
    },
    {
      "epoch": 0.5960264900662252,
      "grad_norm": 4.196674346923828,
      "learning_rate": 1.0924504569398701e-05,
      "loss": 0.4065,
      "step": 90
    },
    {
      "epoch": 0.6622516556291391,
      "grad_norm": 6.525529861450195,
      "learning_rate": 1.0624380817492143e-05,
      "loss": 0.3602,
      "step": 100
    },
    {
      "epoch": 0.7284768211920529,
      "grad_norm": 5.813663005828857,
      "learning_rate": 1.0324257065585586e-05,
      "loss": 0.346,
      "step": 110
    },
    {
      "epoch": 0.7947019867549668,
      "grad_norm": 9.449101448059082,
      "learning_rate": 1.0024133313679028e-05,
      "loss": 0.3193,
      "step": 120
    },
    {
      "epoch": 0.8609271523178808,
      "grad_norm": 7.902575492858887,
      "learning_rate": 9.72400956177247e-06,
      "loss": 0.2817,
      "step": 130
    },
    {
      "epoch": 0.9271523178807947,
      "grad_norm": 15.95044231414795,
      "learning_rate": 9.423885809865913e-06,
      "loss": 0.3306,
      "step": 140
    },
    {
      "epoch": 0.9933774834437086,
      "grad_norm": 13.892196655273438,
      "learning_rate": 9.123762057959354e-06,
      "loss": 0.2988,
      "step": 150
    },
    {
      "epoch": 1.0596026490066226,
      "grad_norm": 7.188504695892334,
      "learning_rate": 8.823638306052798e-06,
      "loss": 0.2199,
      "step": 160
    },
    {
      "epoch": 1.1258278145695364,
      "grad_norm": 3.1561970710754395,
      "learning_rate": 8.52351455414624e-06,
      "loss": 0.3298,
      "step": 170
    },
    {
      "epoch": 1.1920529801324504,
      "grad_norm": 19.009193420410156,
      "learning_rate": 8.223390802239681e-06,
      "loss": 0.1693,
      "step": 180
    },
    {
      "epoch": 1.2582781456953642,
      "grad_norm": 2.284693956375122,
      "learning_rate": 7.923267050333124e-06,
      "loss": 0.2023,
      "step": 190
    },
    {
      "epoch": 1.3245033112582782,
      "grad_norm": 4.272728443145752,
      "learning_rate": 7.623143298426566e-06,
      "loss": 0.2853,
      "step": 200
    },
    {
      "epoch": 1.390728476821192,
      "grad_norm": 11.32766342163086,
      "learning_rate": 7.323019546520008e-06,
      "loss": 0.3141,
      "step": 210
    },
    {
      "epoch": 1.4569536423841059,
      "grad_norm": 11.08414363861084,
      "learning_rate": 7.022895794613451e-06,
      "loss": 0.2792,
      "step": 220
    },
    {
      "epoch": 1.5231788079470199,
      "grad_norm": 5.920989036560059,
      "learning_rate": 6.722772042706893e-06,
      "loss": 0.3166,
      "step": 230
    },
    {
      "epoch": 1.589403973509934,
      "grad_norm": 0.5533216595649719,
      "learning_rate": 6.422648290800336e-06,
      "loss": 0.3667,
      "step": 240
    },
    {
      "epoch": 1.6556291390728477,
      "grad_norm": 18.968542098999023,
      "learning_rate": 6.122524538893778e-06,
      "loss": 0.2296,
      "step": 250
    },
    {
      "epoch": 1.7218543046357615,
      "grad_norm": 19.35597801208496,
      "learning_rate": 5.82240078698722e-06,
      "loss": 0.1773,
      "step": 260
    },
    {
      "epoch": 1.7880794701986755,
      "grad_norm": 19.676998138427734,
      "learning_rate": 5.522277035080662e-06,
      "loss": 0.2639,
      "step": 270
    },
    {
      "epoch": 1.8543046357615895,
      "grad_norm": 20.449947357177734,
      "learning_rate": 5.222153283174105e-06,
      "loss": 0.159,
      "step": 280
    },
    {
      "epoch": 1.9205298013245033,
      "grad_norm": 15.544037818908691,
      "learning_rate": 4.9220295312675465e-06,
      "loss": 0.27,
      "step": 290
    },
    {
      "epoch": 1.9867549668874172,
      "grad_norm": 4.952120780944824,
      "learning_rate": 4.621905779360989e-06,
      "loss": 0.2778,
      "step": 300
    },
    {
      "epoch": 2.052980132450331,
      "grad_norm": 2.252155065536499,
      "learning_rate": 4.3217820274544315e-06,
      "loss": 0.2131,
      "step": 310
    },
    {
      "epoch": 2.119205298013245,
      "grad_norm": 21.395721435546875,
      "learning_rate": 4.021658275547874e-06,
      "loss": 0.1788,
      "step": 320
    },
    {
      "epoch": 2.185430463576159,
      "grad_norm": 0.6863036155700684,
      "learning_rate": 3.721534523641316e-06,
      "loss": 0.0871,
      "step": 330
    },
    {
      "epoch": 2.251655629139073,
      "grad_norm": 5.834164619445801,
      "learning_rate": 3.421410771734758e-06,
      "loss": 0.2124,
      "step": 340
    },
    {
      "epoch": 2.3178807947019866,
      "grad_norm": 0.5352906584739685,
      "learning_rate": 3.1212870198282006e-06,
      "loss": 0.1599,
      "step": 350
    },
    {
      "epoch": 2.384105960264901,
      "grad_norm": 11.872328758239746,
      "learning_rate": 2.8211632679216426e-06,
      "loss": 0.1759,
      "step": 360
    },
    {
      "epoch": 2.4503311258278146,
      "grad_norm": 3.7803878784179688,
      "learning_rate": 2.521039516015085e-06,
      "loss": 0.1537,
      "step": 370
    },
    {
      "epoch": 2.5165562913907285,
      "grad_norm": 9.346169471740723,
      "learning_rate": 2.220915764108527e-06,
      "loss": 0.1941,
      "step": 380
    },
    {
      "epoch": 2.5827814569536423,
      "grad_norm": 24.797744750976562,
      "learning_rate": 1.9207920122019696e-06,
      "loss": 0.1207,
      "step": 390
    },
    {
      "epoch": 2.6490066225165565,
      "grad_norm": 2.1200993061065674,
      "learning_rate": 1.6206682602954117e-06,
      "loss": 0.2366,
      "step": 400
    },
    {
      "epoch": 2.7152317880794703,
      "grad_norm": 15.920022010803223,
      "learning_rate": 1.320544508388854e-06,
      "loss": 0.207,
      "step": 410
    },
    {
      "epoch": 2.781456953642384,
      "grad_norm": 21.114295959472656,
      "learning_rate": 1.0204207564822962e-06,
      "loss": 0.1781,
      "step": 420
    },
    {
      "epoch": 2.847682119205298,
      "grad_norm": 8.547161102294922,
      "learning_rate": 7.202970045757385e-07,
      "loss": 0.2522,
      "step": 430
    },
    {
      "epoch": 2.9139072847682117,
      "grad_norm": 4.652509689331055,
      "learning_rate": 4.2017325266918083e-07,
      "loss": 0.2175,
      "step": 440
    },
    {
      "epoch": 2.980132450331126,
      "grad_norm": 12.955920219421387,
      "learning_rate": 1.200495007626231e-07,
      "loss": 0.0289,
      "step": 450
    }
  ],
  "logging_steps": 10,
  "max_steps": 453,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 475573232563200.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
