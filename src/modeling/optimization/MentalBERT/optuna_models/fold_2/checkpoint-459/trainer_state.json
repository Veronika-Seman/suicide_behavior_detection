{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 459,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06535947712418301,
      "grad_norm": 3.1195287704467773,
      "learning_rate": 1.3329025452320651e-05,
      "loss": 0.6577,
      "step": 10
    },
    {
      "epoch": 0.13071895424836602,
      "grad_norm": 3.599803924560547,
      "learning_rate": 1.3032824886713526e-05,
      "loss": 0.6158,
      "step": 20
    },
    {
      "epoch": 0.19607843137254902,
      "grad_norm": 3.1893959045410156,
      "learning_rate": 1.27366243211064e-05,
      "loss": 0.6021,
      "step": 30
    },
    {
      "epoch": 0.26143790849673204,
      "grad_norm": 4.125646114349365,
      "learning_rate": 1.2440423755499275e-05,
      "loss": 0.4579,
      "step": 40
    },
    {
      "epoch": 0.32679738562091504,
      "grad_norm": 8.047908782958984,
      "learning_rate": 1.214422318989215e-05,
      "loss": 0.524,
      "step": 50
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 8.096323013305664,
      "learning_rate": 1.1848022624285025e-05,
      "loss": 0.4068,
      "step": 60
    },
    {
      "epoch": 0.45751633986928103,
      "grad_norm": 4.394287109375,
      "learning_rate": 1.1551822058677898e-05,
      "loss": 0.3634,
      "step": 70
    },
    {
      "epoch": 0.5228758169934641,
      "grad_norm": 6.265338897705078,
      "learning_rate": 1.1255621493070772e-05,
      "loss": 0.402,
      "step": 80
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 2.799633741378784,
      "learning_rate": 1.0959420927463647e-05,
      "loss": 0.3418,
      "step": 90
    },
    {
      "epoch": 0.6535947712418301,
      "grad_norm": 3.8421895503997803,
      "learning_rate": 1.0663220361856522e-05,
      "loss": 0.2987,
      "step": 100
    },
    {
      "epoch": 0.7189542483660131,
      "grad_norm": 7.81000280380249,
      "learning_rate": 1.0367019796249396e-05,
      "loss": 0.4194,
      "step": 110
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 15.35472583770752,
      "learning_rate": 1.007081923064227e-05,
      "loss": 0.4736,
      "step": 120
    },
    {
      "epoch": 0.8496732026143791,
      "grad_norm": 3.4479761123657227,
      "learning_rate": 9.774618665035144e-06,
      "loss": 0.3987,
      "step": 130
    },
    {
      "epoch": 0.9150326797385621,
      "grad_norm": 5.143584251403809,
      "learning_rate": 9.47841809942802e-06,
      "loss": 0.3982,
      "step": 140
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 3.2715370655059814,
      "learning_rate": 9.182217533820893e-06,
      "loss": 0.3309,
      "step": 150
    },
    {
      "epoch": 1.0457516339869282,
      "grad_norm": 6.332391738891602,
      "learning_rate": 8.886016968213768e-06,
      "loss": 0.3651,
      "step": 160
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 0.8040043115615845,
      "learning_rate": 8.589816402606643e-06,
      "loss": 0.2279,
      "step": 170
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 1.913389801979065,
      "learning_rate": 8.293615836999516e-06,
      "loss": 0.1655,
      "step": 180
    },
    {
      "epoch": 1.2418300653594772,
      "grad_norm": 2.0272488594055176,
      "learning_rate": 7.997415271392392e-06,
      "loss": 0.2103,
      "step": 190
    },
    {
      "epoch": 1.3071895424836601,
      "grad_norm": 10.34743595123291,
      "learning_rate": 7.701214705785265e-06,
      "loss": 0.1791,
      "step": 200
    },
    {
      "epoch": 1.3725490196078431,
      "grad_norm": 0.7429895401000977,
      "learning_rate": 7.40501414017814e-06,
      "loss": 0.263,
      "step": 210
    },
    {
      "epoch": 1.4379084967320261,
      "grad_norm": 8.60314655303955,
      "learning_rate": 7.1088135745710145e-06,
      "loss": 0.2149,
      "step": 220
    },
    {
      "epoch": 1.5032679738562091,
      "grad_norm": 8.170759201049805,
      "learning_rate": 6.812613008963888e-06,
      "loss": 0.3133,
      "step": 230
    },
    {
      "epoch": 1.5686274509803921,
      "grad_norm": 6.898587226867676,
      "learning_rate": 6.516412443356763e-06,
      "loss": 0.2488,
      "step": 240
    },
    {
      "epoch": 1.6339869281045751,
      "grad_norm": 8.899474143981934,
      "learning_rate": 6.220211877749638e-06,
      "loss": 0.1354,
      "step": 250
    },
    {
      "epoch": 1.6993464052287581,
      "grad_norm": 4.102848052978516,
      "learning_rate": 5.924011312142512e-06,
      "loss": 0.343,
      "step": 260
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 9.421041488647461,
      "learning_rate": 5.627810746535386e-06,
      "loss": 0.27,
      "step": 270
    },
    {
      "epoch": 1.8300653594771243,
      "grad_norm": 0.7955301403999329,
      "learning_rate": 5.331610180928261e-06,
      "loss": 0.2484,
      "step": 280
    },
    {
      "epoch": 1.8954248366013071,
      "grad_norm": 12.691356658935547,
      "learning_rate": 5.035409615321135e-06,
      "loss": 0.2902,
      "step": 290
    },
    {
      "epoch": 1.9607843137254903,
      "grad_norm": 9.342390060424805,
      "learning_rate": 4.73920904971401e-06,
      "loss": 0.4299,
      "step": 300
    },
    {
      "epoch": 2.026143790849673,
      "grad_norm": 0.5671582221984863,
      "learning_rate": 4.443008484106884e-06,
      "loss": 0.1569,
      "step": 310
    },
    {
      "epoch": 2.0915032679738563,
      "grad_norm": 5.611394882202148,
      "learning_rate": 4.146807918499758e-06,
      "loss": 0.2185,
      "step": 320
    },
    {
      "epoch": 2.156862745098039,
      "grad_norm": 0.8191227316856384,
      "learning_rate": 3.8506073528926326e-06,
      "loss": 0.2043,
      "step": 330
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 1.7857482433319092,
      "learning_rate": 3.5544067872855072e-06,
      "loss": 0.1571,
      "step": 340
    },
    {
      "epoch": 2.287581699346405,
      "grad_norm": 18.26369857788086,
      "learning_rate": 3.2582062216783815e-06,
      "loss": 0.179,
      "step": 350
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 13.76111125946045,
      "learning_rate": 2.962005656071256e-06,
      "loss": 0.1073,
      "step": 360
    },
    {
      "epoch": 2.418300653594771,
      "grad_norm": 4.512839317321777,
      "learning_rate": 2.6658050904641304e-06,
      "loss": 0.1582,
      "step": 370
    },
    {
      "epoch": 2.4836601307189543,
      "grad_norm": 16.39946937561035,
      "learning_rate": 2.369604524857005e-06,
      "loss": 0.1521,
      "step": 380
    },
    {
      "epoch": 2.549019607843137,
      "grad_norm": 0.8012728095054626,
      "learning_rate": 2.073403959249879e-06,
      "loss": 0.1802,
      "step": 390
    },
    {
      "epoch": 2.6143790849673203,
      "grad_norm": 12.295174598693848,
      "learning_rate": 1.7772033936427536e-06,
      "loss": 0.1524,
      "step": 400
    },
    {
      "epoch": 2.6797385620915035,
      "grad_norm": 3.061204195022583,
      "learning_rate": 1.481002828035628e-06,
      "loss": 0.2617,
      "step": 410
    },
    {
      "epoch": 2.7450980392156863,
      "grad_norm": 7.573996543884277,
      "learning_rate": 1.1848022624285026e-06,
      "loss": 0.1298,
      "step": 420
    },
    {
      "epoch": 2.810457516339869,
      "grad_norm": 19.125947952270508,
      "learning_rate": 8.886016968213768e-07,
      "loss": 0.1167,
      "step": 430
    },
    {
      "epoch": 2.8758169934640523,
      "grad_norm": 7.6010894775390625,
      "learning_rate": 5.924011312142513e-07,
      "loss": 0.2406,
      "step": 440
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 6.183414459228516,
      "learning_rate": 2.9620056560712564e-07,
      "loss": 0.1485,
      "step": 450
    }
  ],
  "logging_steps": 10,
  "max_steps": 459,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 481098564725760.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
