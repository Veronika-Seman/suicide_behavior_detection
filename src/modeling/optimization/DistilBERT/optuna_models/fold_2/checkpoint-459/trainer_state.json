{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 459,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06535947712418301,
      "grad_norm": 1.3101599216461182,
      "learning_rate": 3.861080042137247e-05,
      "loss": 0.6849,
      "step": 10
    },
    {
      "epoch": 0.13071895424836602,
      "grad_norm": 4.878993511199951,
      "learning_rate": 3.775278263423086e-05,
      "loss": 0.6627,
      "step": 20
    },
    {
      "epoch": 0.19607843137254902,
      "grad_norm": 3.882507801055908,
      "learning_rate": 3.689476484708925e-05,
      "loss": 0.6648,
      "step": 30
    },
    {
      "epoch": 0.26143790849673204,
      "grad_norm": 4.143232345581055,
      "learning_rate": 3.603674705994764e-05,
      "loss": 0.4491,
      "step": 40
    },
    {
      "epoch": 0.32679738562091504,
      "grad_norm": 6.544116973876953,
      "learning_rate": 3.517872927280603e-05,
      "loss": 0.6502,
      "step": 50
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 8.22570514678955,
      "learning_rate": 3.432071148566442e-05,
      "loss": 0.3622,
      "step": 60
    },
    {
      "epoch": 0.45751633986928103,
      "grad_norm": 9.52458381652832,
      "learning_rate": 3.346269369852281e-05,
      "loss": 0.3334,
      "step": 70
    },
    {
      "epoch": 0.5228758169934641,
      "grad_norm": 3.6455390453338623,
      "learning_rate": 3.26046759113812e-05,
      "loss": 0.3595,
      "step": 80
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 6.54341459274292,
      "learning_rate": 3.1746658124239585e-05,
      "loss": 0.4169,
      "step": 90
    },
    {
      "epoch": 0.6535947712418301,
      "grad_norm": 6.27049446105957,
      "learning_rate": 3.0888640337097975e-05,
      "loss": 0.3289,
      "step": 100
    },
    {
      "epoch": 0.7189542483660131,
      "grad_norm": 8.975879669189453,
      "learning_rate": 3.003062254995637e-05,
      "loss": 0.5225,
      "step": 110
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 5.161592960357666,
      "learning_rate": 2.9172604762814755e-05,
      "loss": 0.4537,
      "step": 120
    },
    {
      "epoch": 0.8496732026143791,
      "grad_norm": 1.5920614004135132,
      "learning_rate": 2.8314586975673145e-05,
      "loss": 0.3648,
      "step": 130
    },
    {
      "epoch": 0.9150326797385621,
      "grad_norm": 3.677670478820801,
      "learning_rate": 2.745656918853154e-05,
      "loss": 0.3912,
      "step": 140
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 1.8938899040222168,
      "learning_rate": 2.6598551401389926e-05,
      "loss": 0.3542,
      "step": 150
    },
    {
      "epoch": 1.0457516339869282,
      "grad_norm": 7.011028289794922,
      "learning_rate": 2.5740533614248316e-05,
      "loss": 0.4093,
      "step": 160
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 1.074393630027771,
      "learning_rate": 2.4882515827106706e-05,
      "loss": 0.2577,
      "step": 170
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 0.669994056224823,
      "learning_rate": 2.4024498039965093e-05,
      "loss": 0.1202,
      "step": 180
    },
    {
      "epoch": 1.2418300653594772,
      "grad_norm": 0.20601022243499756,
      "learning_rate": 2.3166480252823486e-05,
      "loss": 0.3373,
      "step": 190
    },
    {
      "epoch": 1.3071895424836601,
      "grad_norm": 4.970333099365234,
      "learning_rate": 2.2308462465681873e-05,
      "loss": 0.158,
      "step": 200
    },
    {
      "epoch": 1.3725490196078431,
      "grad_norm": 1.1492459774017334,
      "learning_rate": 2.1450444678540263e-05,
      "loss": 0.4059,
      "step": 210
    },
    {
      "epoch": 1.4379084967320261,
      "grad_norm": 3.638228178024292,
      "learning_rate": 2.0592426891398653e-05,
      "loss": 0.2474,
      "step": 220
    },
    {
      "epoch": 1.5032679738562091,
      "grad_norm": 4.715223789215088,
      "learning_rate": 1.973440910425704e-05,
      "loss": 0.3672,
      "step": 230
    },
    {
      "epoch": 1.5686274509803921,
      "grad_norm": 4.820034503936768,
      "learning_rate": 1.887639131711543e-05,
      "loss": 0.2853,
      "step": 240
    },
    {
      "epoch": 1.6339869281045751,
      "grad_norm": 7.762660503387451,
      "learning_rate": 1.801837352997382e-05,
      "loss": 0.1505,
      "step": 250
    },
    {
      "epoch": 1.6993464052287581,
      "grad_norm": 0.617062509059906,
      "learning_rate": 1.716035574283221e-05,
      "loss": 0.262,
      "step": 260
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 13.508370399475098,
      "learning_rate": 1.63023379556906e-05,
      "loss": 0.2659,
      "step": 270
    },
    {
      "epoch": 1.8300653594771243,
      "grad_norm": 2.132129430770874,
      "learning_rate": 1.5444320168548987e-05,
      "loss": 0.2275,
      "step": 280
    },
    {
      "epoch": 1.8954248366013071,
      "grad_norm": 13.461458206176758,
      "learning_rate": 1.4586302381407378e-05,
      "loss": 0.2668,
      "step": 290
    },
    {
      "epoch": 1.9607843137254903,
      "grad_norm": 1.5481945276260376,
      "learning_rate": 1.372828459426577e-05,
      "loss": 0.3043,
      "step": 300
    },
    {
      "epoch": 2.026143790849673,
      "grad_norm": 0.2587982416152954,
      "learning_rate": 1.2870266807124158e-05,
      "loss": 0.1559,
      "step": 310
    },
    {
      "epoch": 2.0915032679738563,
      "grad_norm": 13.840348243713379,
      "learning_rate": 1.2012249019982546e-05,
      "loss": 0.237,
      "step": 320
    },
    {
      "epoch": 2.156862745098039,
      "grad_norm": 0.169224351644516,
      "learning_rate": 1.1154231232840937e-05,
      "loss": 0.1615,
      "step": 330
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 7.3968634605407715,
      "learning_rate": 1.0296213445699327e-05,
      "loss": 0.1471,
      "step": 340
    },
    {
      "epoch": 2.287581699346405,
      "grad_norm": 0.6428321003913879,
      "learning_rate": 9.438195658557715e-06,
      "loss": 0.0484,
      "step": 350
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 31.180191040039062,
      "learning_rate": 8.580177871416105e-06,
      "loss": 0.1395,
      "step": 360
    },
    {
      "epoch": 2.418300653594771,
      "grad_norm": 2.0342600345611572,
      "learning_rate": 7.722160084274494e-06,
      "loss": 0.0744,
      "step": 370
    },
    {
      "epoch": 2.4836601307189543,
      "grad_norm": 10.450353622436523,
      "learning_rate": 6.864142297132885e-06,
      "loss": 0.1328,
      "step": 380
    },
    {
      "epoch": 2.549019607843137,
      "grad_norm": 0.7451745867729187,
      "learning_rate": 6.006124509991273e-06,
      "loss": 0.2024,
      "step": 390
    },
    {
      "epoch": 2.6143790849673203,
      "grad_norm": 18.3724365234375,
      "learning_rate": 5.148106722849663e-06,
      "loss": 0.2461,
      "step": 400
    },
    {
      "epoch": 2.6797385620915035,
      "grad_norm": 0.1256445348262787,
      "learning_rate": 4.290088935708053e-06,
      "loss": 0.3404,
      "step": 410
    },
    {
      "epoch": 2.7450980392156863,
      "grad_norm": 2.7996859550476074,
      "learning_rate": 3.4320711485664424e-06,
      "loss": 0.0625,
      "step": 420
    },
    {
      "epoch": 2.810457516339869,
      "grad_norm": 14.005690574645996,
      "learning_rate": 2.5740533614248317e-06,
      "loss": 0.0738,
      "step": 430
    },
    {
      "epoch": 2.8758169934640523,
      "grad_norm": 0.22702637314796448,
      "learning_rate": 1.7160355742832212e-06,
      "loss": 0.0968,
      "step": 440
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 0.08499809354543686,
      "learning_rate": 8.580177871416106e-07,
      "loss": 0.0767,
      "step": 450
    }
  ],
  "logging_steps": 10,
  "max_steps": 459,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 242216638442496.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
