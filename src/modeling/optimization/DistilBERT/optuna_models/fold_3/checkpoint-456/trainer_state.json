{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 456,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06578947368421052,
      "grad_norm": 1.4566594362258911,
      "learning_rate": 3.860572005289598e-05,
      "loss": 0.6813,
      "step": 10
    },
    {
      "epoch": 0.13157894736842105,
      "grad_norm": 4.956287384033203,
      "learning_rate": 3.774205741189159e-05,
      "loss": 0.5996,
      "step": 20
    },
    {
      "epoch": 0.19736842105263158,
      "grad_norm": 2.308013439178467,
      "learning_rate": 3.6878394770887205e-05,
      "loss": 0.5318,
      "step": 30
    },
    {
      "epoch": 0.2631578947368421,
      "grad_norm": 7.5309553146362305,
      "learning_rate": 3.6014732129882826e-05,
      "loss": 0.5537,
      "step": 40
    },
    {
      "epoch": 0.32894736842105265,
      "grad_norm": 2.9004428386688232,
      "learning_rate": 3.515106948887844e-05,
      "loss": 0.4968,
      "step": 50
    },
    {
      "epoch": 0.39473684210526316,
      "grad_norm": 2.317641019821167,
      "learning_rate": 3.4287406847874054e-05,
      "loss": 0.454,
      "step": 60
    },
    {
      "epoch": 0.4605263157894737,
      "grad_norm": 9.93815803527832,
      "learning_rate": 3.3423744206869674e-05,
      "loss": 0.4357,
      "step": 70
    },
    {
      "epoch": 0.5263157894736842,
      "grad_norm": 4.265872001647949,
      "learning_rate": 3.256008156586529e-05,
      "loss": 0.4071,
      "step": 80
    },
    {
      "epoch": 0.5921052631578947,
      "grad_norm": 10.96202564239502,
      "learning_rate": 3.16964189248609e-05,
      "loss": 0.3755,
      "step": 90
    },
    {
      "epoch": 0.6578947368421053,
      "grad_norm": 2.290130853652954,
      "learning_rate": 3.083275628385652e-05,
      "loss": 0.5416,
      "step": 100
    },
    {
      "epoch": 0.7236842105263158,
      "grad_norm": 6.703827381134033,
      "learning_rate": 2.9969093642852133e-05,
      "loss": 0.3098,
      "step": 110
    },
    {
      "epoch": 0.7894736842105263,
      "grad_norm": 13.552069664001465,
      "learning_rate": 2.910543100184775e-05,
      "loss": 0.3217,
      "step": 120
    },
    {
      "epoch": 0.8552631578947368,
      "grad_norm": 2.9429659843444824,
      "learning_rate": 2.8241768360843364e-05,
      "loss": 0.4728,
      "step": 130
    },
    {
      "epoch": 0.9210526315789473,
      "grad_norm": 4.678024768829346,
      "learning_rate": 2.737810571983898e-05,
      "loss": 0.4028,
      "step": 140
    },
    {
      "epoch": 0.9868421052631579,
      "grad_norm": 4.365315914154053,
      "learning_rate": 2.65144430788346e-05,
      "loss": 0.3365,
      "step": 150
    },
    {
      "epoch": 1.0526315789473684,
      "grad_norm": 9.629110336303711,
      "learning_rate": 2.5650780437830213e-05,
      "loss": 0.2138,
      "step": 160
    },
    {
      "epoch": 1.118421052631579,
      "grad_norm": 16.373886108398438,
      "learning_rate": 2.478711779682583e-05,
      "loss": 0.247,
      "step": 170
    },
    {
      "epoch": 1.1842105263157894,
      "grad_norm": 9.965733528137207,
      "learning_rate": 2.392345515582144e-05,
      "loss": 0.2202,
      "step": 180
    },
    {
      "epoch": 1.25,
      "grad_norm": 5.179160118103027,
      "learning_rate": 2.305979251481706e-05,
      "loss": 0.4099,
      "step": 190
    },
    {
      "epoch": 1.3157894736842106,
      "grad_norm": 0.47364211082458496,
      "learning_rate": 2.219612987381268e-05,
      "loss": 0.2539,
      "step": 200
    },
    {
      "epoch": 1.381578947368421,
      "grad_norm": 14.233207702636719,
      "learning_rate": 2.133246723280829e-05,
      "loss": 0.371,
      "step": 210
    },
    {
      "epoch": 1.4473684210526316,
      "grad_norm": 1.3880994319915771,
      "learning_rate": 2.0468804591803906e-05,
      "loss": 0.2432,
      "step": 220
    },
    {
      "epoch": 1.513157894736842,
      "grad_norm": 22.308536529541016,
      "learning_rate": 1.9605141950799523e-05,
      "loss": 0.2332,
      "step": 230
    },
    {
      "epoch": 1.5789473684210527,
      "grad_norm": 5.8836259841918945,
      "learning_rate": 1.8741479309795137e-05,
      "loss": 0.4426,
      "step": 240
    },
    {
      "epoch": 1.6447368421052633,
      "grad_norm": 4.092595100402832,
      "learning_rate": 1.7877816668790754e-05,
      "loss": 0.3008,
      "step": 250
    },
    {
      "epoch": 1.7105263157894737,
      "grad_norm": 11.971457481384277,
      "learning_rate": 1.7014154027786372e-05,
      "loss": 0.2285,
      "step": 260
    },
    {
      "epoch": 1.776315789473684,
      "grad_norm": 0.7237919569015503,
      "learning_rate": 1.6150491386781986e-05,
      "loss": 0.1089,
      "step": 270
    },
    {
      "epoch": 1.8421052631578947,
      "grad_norm": 0.33204349875450134,
      "learning_rate": 1.52868287457776e-05,
      "loss": 0.2123,
      "step": 280
    },
    {
      "epoch": 1.9078947368421053,
      "grad_norm": 0.38423046469688416,
      "learning_rate": 1.4423166104773217e-05,
      "loss": 0.2304,
      "step": 290
    },
    {
      "epoch": 1.973684210526316,
      "grad_norm": 0.773402214050293,
      "learning_rate": 1.3559503463768834e-05,
      "loss": 0.2082,
      "step": 300
    },
    {
      "epoch": 2.039473684210526,
      "grad_norm": 0.7915081977844238,
      "learning_rate": 1.269584082276445e-05,
      "loss": 0.1661,
      "step": 310
    },
    {
      "epoch": 2.1052631578947367,
      "grad_norm": 2.1162939071655273,
      "learning_rate": 1.1832178181760063e-05,
      "loss": 0.1432,
      "step": 320
    },
    {
      "epoch": 2.1710526315789473,
      "grad_norm": 10.376249313354492,
      "learning_rate": 1.0968515540755679e-05,
      "loss": 0.1974,
      "step": 330
    },
    {
      "epoch": 2.236842105263158,
      "grad_norm": 2.883033514022827,
      "learning_rate": 1.0104852899751296e-05,
      "loss": 0.2291,
      "step": 340
    },
    {
      "epoch": 2.3026315789473686,
      "grad_norm": 0.1347406506538391,
      "learning_rate": 9.241190258746912e-06,
      "loss": 0.0731,
      "step": 350
    },
    {
      "epoch": 2.3684210526315788,
      "grad_norm": 1.9166054725646973,
      "learning_rate": 8.377527617742527e-06,
      "loss": 0.1285,
      "step": 360
    },
    {
      "epoch": 2.4342105263157894,
      "grad_norm": 14.149690628051758,
      "learning_rate": 7.513864976738144e-06,
      "loss": 0.1595,
      "step": 370
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.3561733365058899,
      "learning_rate": 6.650202335733758e-06,
      "loss": 0.1176,
      "step": 380
    },
    {
      "epoch": 2.5657894736842106,
      "grad_norm": 0.4440368115901947,
      "learning_rate": 5.786539694729375e-06,
      "loss": 0.0935,
      "step": 390
    },
    {
      "epoch": 2.6315789473684212,
      "grad_norm": 0.3141789734363556,
      "learning_rate": 4.92287705372499e-06,
      "loss": 0.104,
      "step": 400
    },
    {
      "epoch": 2.6973684210526314,
      "grad_norm": 0.16296666860580444,
      "learning_rate": 4.059214412720606e-06,
      "loss": 0.0158,
      "step": 410
    },
    {
      "epoch": 2.763157894736842,
      "grad_norm": 3.8924455642700195,
      "learning_rate": 3.195551771716222e-06,
      "loss": 0.2219,
      "step": 420
    },
    {
      "epoch": 2.8289473684210527,
      "grad_norm": 8.468025207519531,
      "learning_rate": 2.3318891307118374e-06,
      "loss": 0.2749,
      "step": 430
    },
    {
      "epoch": 2.8947368421052633,
      "grad_norm": 0.7671788930892944,
      "learning_rate": 1.4682264897074532e-06,
      "loss": 0.2089,
      "step": 440
    },
    {
      "epoch": 2.9605263157894735,
      "grad_norm": 1.3505390882492065,
      "learning_rate": 6.045638487030689e-07,
      "loss": 0.0957,
      "step": 450
    }
  ],
  "logging_steps": 10,
  "max_steps": 456,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 241024431854592.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
